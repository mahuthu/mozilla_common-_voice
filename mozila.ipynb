{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_STelCTqpsvs",
        "outputId": "4b943609-39b2-4051-f661-c18dcd874fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7e160pls3zZ",
        "outputId": "62ee2f44-217b-4476-8f38-1edf9c088152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAHwxCarxPpp",
        "outputId": "41a75f93-af01-4094-dbd7-32fc212586ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "856m_R4knqgi",
        "outputId": "b1faccf9-8307-46b0-c608-92d16b523276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "Zjz_jy8inNEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8dy5Hpx-QEY",
        "outputId": "3a69d108-12d1-4093-e1df-b81446c6307a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tWyeHzt_65P",
        "outputId": "6d73d15e-5adb-454b-9aba-7d9f98a4b59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchaudio) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchaudio) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PosnhTXMAPxL",
        "outputId": "e6cba8c8-7337-4e59-913c-8d2c59b7bad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oshvvslkAbfL",
        "outputId": "e6631b45-626a-4cbb-bf02-14dfef578e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "owR0cJhJNWiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_dataset = load_dataset('mozilla-foundation/common_voice_13_0', \"sw\", split='train' )\n",
        "validation_dataset = load_dataset('mozilla-foundation/common_voice_13_0', \"sw\", split='validation')\n",
        "test_dataset = load_dataset('mozilla-foundation/common_voice_13_0', \"sw\", split='test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exRNwVQPns0K",
        "outputId": "0db9cd1f-9ba5-484e-98f8-f4044aa8a812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for mozilla-foundation/common_voice_13_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_13_0\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JLWxbW2vTRR",
        "outputId": "04a18f32-7df8-4209-d13a-b5b582232ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
              "    num_rows: 34980\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Function to show random elements from the train, validate, and test dataset"
      ],
      "metadata": {
        "id": "QP52gpbTdQ3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import ClassLabel\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "fGGSEYMeqxxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_random_elements(train_dataset)"
      ],
      "metadata": {
        "id": "sOhJQgsscvhK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f30dd56-badd-4d4e-e67a-8e74088fbeb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>path</th>\n",
              "      <th>audio</th>\n",
              "      <th>sentence</th>\n",
              "      <th>up_votes</th>\n",
              "      <th>down_votes</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accent</th>\n",
              "      <th>locale</th>\n",
              "      <th>segment</th>\n",
              "      <th>variant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0e19d024efd1bd00fdcd20209935f3472caeec3985e168c691179a4fe8768492a0cc3de66732c2ffbfaca7fc9ea345e3870c0c072bc0ad5ffbcd8602a168894f</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_29936537.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_29936537.mp3', 'array': [0.0, -5.968558980384842e-13, -1.0231815394945443e-12, -7.673861546209082e-13, -3.410605131648481e-13, -2.5579538487363607e-13, -9.947598300641403e-14, -3.836930773104541e-13, -4.689582056016661e-13, -4.547473508864641e-13, -8.526512829121202e-14, 4.263256414560601e-13, 8.526512829121202e-13, 9.094947017729282e-13, 6.252776074688882e-13, -4.973799150320701e-13, -1.6200374375330284e-12, -2.2453150450019166e-12, -2.5721647034515627e-12, -3.154809746774845e-12, -4.092726157978177e-12, -4.447997525858227e-12, -4.206412995699793e-12, -2.8279600883251987e-12, -1.2789769243681803e-13, 3.083755473198835e-12, 5.6132876125047915e-12, 6.750155989720952e-12, 6.423306331271306e-12, 5.9969806898152456e-12, 6.45172804070171e-12, 6.94910795573378e-12, 5.4285465012071654e-12, 1.7905676941154525e-12, -2.7569058147491887e-12, -6.536993168992922e-12, -7.389644451905042e-12, -3.751665644813329e-12, 1.5347723092418164e-12, 5.201172825763933e-12, 5.4001247917767614e-12, 3.353761712787673e-12, 1.4068746168049984e-12, 3.296918293926865e-12, 1.0402345651527867e-11, 1.8630430531629827e-11, 2.523847797419876e-11, 3.007016857736744e-11, 3.182165642101609e-11, 3.069544618483633e-11, 2.984279490192421e-11, 2.8535396268125623e-11, 2.3021584638627246e-11, 1.5624834759364603e-11, 1.56035184772918e-11, 2.8251179173821583e-11, 5.077538389741676e-11, 7.229061793623259e-11, 7.958078640513122e-11, 6.787104211980477e-11, 4.7350567911053076e-11, 3.794298208958935e-11, 5.444888984129648e-11, 9.015366231324151e-11, 1.1480949524411699e-10, 9.612222129362635e-11, 2.560796019679401e-11, -7.199218998721335e-11, -1.4559020655724453e-10, -1.4870238373987377e-10, -7.861444828449748e-11, 1.361399881716352e-11, 5.680078629666241e-11, 9.78772618509538e-12, -1.0643930181686301e-10, -2.163460521842353e-10, -2.381170816079248e-10, -1.4159695638227277e-10, 3.041122909053229e-11, 1.8991386241395958e-10, 2.616502570162993e-10, 2.3203483578981832e-10, 1.5412382481372333e-10, 1.035864727327862e-10, 1.2497736179284402e-10, 2.028741619142238e-10, 2.771685103652999e-10, 2.9383784294623183e-10, 2.452509306749562e-10, 1.7024603948812e-10, 1.197690835397225e-10, 1.2249756764504127e-10, 1.6854073692229576e-10, 2.2606627680943348e-10, 2.7267788027529605e-10, 3.072386789426673e-10, 3.3514879760332406e-10, 3.5083758120890707e-10, 3.319655661471188e-10, 2.531663767513237e-10, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Abeid Amani Karume akiwa na umri wa miaka minne</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>729c66e7f38e458f1704244f7ab4b0f81a2af1eedaa9e7f746a43ba1536666854acde46b7cfa744e77ae56660cb6a05f07bff4d2cce5b89c42e797dc5d3b1eb2</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_30631040.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_30631040.mp3', 'array': [7.105427357601002e-15, -3.552713678800501e-14, 5.684341886080802e-14, 1.7053025658242404e-13, 3.552713678800501e-13, 4.831690603168681e-13, 4.405364961712621e-13, 3.552713678800501e-13, 2.1671553440683056e-13, -1.1368683772161603e-13, -5.080380560684716e-13, -7.958078640513122e-13, -9.876544027065393e-13, -1.0977885267493548e-12, -1.1652900866465643e-12, -1.3713474800169934e-12, -1.623590151211829e-12, -1.5418777365994174e-12, -1.1155520951433573e-12, -7.673861546209082e-13, -6.679101716144942e-13, -4.547473508864641e-13, -1.7053025658242404e-13, -5.684341886080802e-14, -2.842170943040401e-14, 1.1368683772161603e-13, 3.197442310920451e-13, 6.039613253960852e-13, 1.0444978215673473e-12, 1.7337242752546445e-12, 2.7640112421067897e-12, 4.305888978706207e-12, 5.8832938520936295e-12, 6.586731160496129e-12, 6.444622613344109e-12, 6.149747378003667e-12, 6.021849685566849e-12, 5.559996907322784e-12, 4.0678571622265736e-12, 1.2470025012589758e-12, -2.6716406864579767e-12, -6.608047442568932e-12, -8.990141964204668e-12, -8.87023787754515e-12, -6.629363724641735e-12, -3.765876499528531e-12, -1.2860823517257813e-12, 9.00612917575927e-13, 3.4230396295242826e-12, 6.572520305780927e-12, 9.546141654936946e-12, 1.1315393066979595e-11, 1.1397105481592007e-11, 9.947598300641403e-12, 6.494360604847316e-12, 2.1174173525650986e-12, 5.400124791776761e-13, 5.144329406903125e-12, 1.411137873219559e-11, 2.1685764295398258e-11, 2.3888446776254568e-11, 2.19912976717751e-11, 2.029310053330846e-11, 1.963940121640917e-11, 1.5120349416974932e-11, 4.050093593832571e-12, -8.981260180007666e-12, -1.6441958905488718e-11, -1.3535839116229909e-11, 1.8332002582610585e-12, 2.737010618147906e-11, 5.31770183442859e-11, 6.539835339935962e-11, 5.5784710184525466e-11, 2.717115421546623e-11, -8.100187187665142e-12, -3.5356606531422585e-11, -4.445155354915187e-11, -3.170441686961567e-11, -2.7995383788947947e-12, 2.6403768060845323e-11, 4.285993782104924e-11, 5.030642569181509e-11, 6.164668775454629e-11, 7.631228982063476e-11, 7.86783971307159e-11, 5.88613602303667e-11, 2.9316993277461734e-11, 1.3173462320992257e-11, 1.907807245515869e-11, 3.6131098113401094e-11, 5.274358727547224e-11, 6.716760481140227e-11, 7.605649443576112e-11, 6.997424861765467e-11, 4.696687483374262e-11, 2.0406787371030077e-11, 4.874323167314287e-12, -1.9895196601282805e-12, -1.7109869077103212e-11, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Mwezi uliopita Messi alituma jezi yake alioisaini kwa kampuni ya dawa nchini China Sinovac</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>005601a78e31ce8c643fce823fc37cf28a16d375c09a82ef5da7becb99468da18863a07347a03de03a325c37990d601a59795290d2a8595ce9c69c6b8466f716</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_29950041.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_29950041.mp3', 'array': [-1.3010426069826053e-17, 1.0408340855860843e-16, 1.6653345369377348e-16, 1.249000902703301e-16, -5.551115123125783e-17, -7.45931094670027e-17, -6.938893903907228e-18, 6.938893903907228e-18, -6.245004513516506e-17, 6.245004513516506e-17, 2.3592239273284576e-16, -4.85722573273506e-17, -4.0939474033052647e-16, -1.8735013540549517e-16, 3.608224830031759e-16, 3.400058012914542e-16, -1.7520707107365752e-16, -3.677613769070831e-16, -1.3877787807814457e-17, 2.1510571102112408e-16, -9.367506770274758e-17, -3.608224830031759e-16, 2.1510571102112408e-16, 6.175615574477433e-16, -1.0408340855860843e-17, -7.598088824778415e-16, -2.498001805406602e-16, 5.655198531684391e-16, 2.3592239273284576e-16, -4.996003610813204e-16, 3.122502256758253e-17, 1.0200174038743626e-15, 3.0531133177191805e-16, -1.609823385706477e-15, -1.519617764955683e-15, 1.3183898417423734e-15, 2.6922908347160046e-15, 3.3306690738754696e-16, -2.310651670001107e-15, -1.4641066137244252e-15, 4.996003610813204e-16, 6.800116025829084e-16, 3.191891195797325e-16, 1.3322676295501878e-15, 1.2455314557513475e-15, -2.095545958979983e-15, -4.295175326518574e-15, -1.1449174941446927e-16, 5.4539706084710815e-15, 2.976785484776201e-15, -4.173744683200198e-15, -3.635980405647388e-15, 3.400058012914542e-15, 2.3349377986647823e-15, -6.7931771319251766e-15, -5.048045315092509e-15, 1.1334683192032458e-14, 1.5862311464331924e-14, -7.563394355258879e-15, -2.8754776337791554e-14, -9.495876307497042e-15, 3.090930289495475e-14, 3.297188910789117e-14, -1.3714723801072637e-14, -4.633446404334052e-14, -1.6833756610878936e-14, 3.652113333973972e-14, 4.23792945181134e-14, -5.998673779927799e-15, -4.547404119925602e-14, -2.853967062677043e-14, 2.1812412986932372e-14, 4.6841003298325745e-14, 1.8408885527065877e-14, -3.439609708166813e-14, -5.2437221231826925e-14, -6.1999017031411086e-15, 5.810976699827108e-14, 5.638545186315014e-14, -2.379693664344984e-14, -8.328754352859846e-14, -3.427293171487378e-14, 6.591949208711867e-14, 8.015463293098435e-14, -1.269123695024632e-14, -8.290590436388356e-14, -3.8163916471489756e-14, 4.691386168431677e-14, 5.346070808265324e-14, -7.382983113757291e-15, -3.535366444040733e-14, -5.488665077990618e-15, 1.434269369937624e-14, -4.8780424144467815e-15, -1.379452108096757e-14, 1.1844691893969639e-14, 2.4980018054066022e-14, -1.4502288259166107e-15, -2.4355517602714372e-14, -1.0810796702287462e-14, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Maumau ilianzishwa mwanzoni mwa miaka ya hamsini na kabila la wakikuyu</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9b9041703d521a14082f7df995dbb62f10e8bc340c3305638b1087ff58ae6ffeaa40743c6e19794a969dee154851e809aaadead83d5fda6baa400fac5370f621</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_31252300.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_31252300.mp3', 'array': [1.4210854715202004e-14, -5.400124791776761e-13, -7.958078640513122e-13, -8.526512829121202e-13, -5.115907697472721e-13, -7.105427357601002e-13, -8.810729923425242e-13, -9.237055564881302e-13, -1.0089706847793423e-12, -7.105427357601002e-13, -5.258016244624741e-13, 5.684341886080802e-14, 1.4495071809506044e-12, 2.5863755581667647e-12, 2.7000623958883807e-12, 2.4300561562995426e-12, 2.2168933355715126e-12, 1.1297629498585593e-12, -2.984279490192421e-13, -1.3216094885137863e-12, -1.3216094885137863e-12, -8.384404281969182e-13, -3.410605131648481e-13, 5.684341886080802e-14, -5.684341886080802e-14, 1.7053025658242404e-13, 8.526512829121202e-13, 1.5916157281026244e-12, 2.4300561562995426e-12, 2.7000623958883807e-12, 1.0516032489249483e-12, -2.6290081223123707e-12, -7.787548383930698e-12, -1.2605028132384177e-11, -1.5091927707544528e-11, -1.4154011296341196e-11, -9.777068044058979e-12, -2.4442670110147446e-12, 6.16751094639767e-12, 1.247713043994736e-11, 1.5518253349000588e-11, 1.6257217794191092e-11, 1.6086687537608668e-11, 1.5475620784854982e-11, 1.6267875935227494e-11, 1.779199010343291e-11, 1.878674993349705e-11, 2.006572685786523e-11, 2.1998403099132702e-11, 2.3931079340400174e-11, 2.6076918402395677e-11, 2.7348789899406256e-11, 2.475530891388189e-11, 1.793409865058493e-11, 8.554934538551606e-12, -2.6716406864579767e-12, -1.3244516594568267e-11, -1.9554136088117957e-11, -2.2865265236760024e-11, -2.7824853532365523e-11, -3.8056668927310966e-11, -5.275069270282984e-11, -6.752998160663992e-11, -7.493383691326017e-11, -6.829736776126083e-11, -4.573053047352005e-11, -1.0615508472255897e-11, 2.6631141736288555e-11, 5.2011728257639334e-11, 5.854872142663226e-11, 4.951061782776378e-11, 3.4503955248510465e-11, 2.4982682589325123e-11, 2.680167199287098e-11, 3.637978807091713e-11, 4.334310688136611e-11, 3.444711182964966e-11, 1.8189894035458565e-12, -5.0107473725802265e-11, -1.0459189070388675e-10, -1.4375700629898347e-10, -1.5836576494621113e-10, -1.5054979485285003e-10, -1.3238832252682187e-10, -1.1891643225681037e-10, -1.1860379345307592e-10, -1.2775558388966601e-10, -1.3292833500599954e-10, -1.2033751772833057e-10, -8.643752380521619e-11, -3.787192781601334e-11, 1.5432988220709376e-11, 6.109246442065341e-11, 9.22000253922306e-11, 1.1142731182189891e-10, 1.2232703738845885e-10, 1.234354840562446e-10, 1.148947603724082e-10, 1.0308554010407533e-10, 9.50706180447014e-11, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Lazima kuwe na Wandebele nchini Zimbabwe na wote waitwe Wazimbabwe</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1e4b380e964ac30ff674ad270587c490d602a633472d9b2098af31e93bfbd050281ef2b57441afb1ed5b72c15f0d051492a8ccc626a1eb16c026bc2ab6e89033</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_30584760.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_30584760.mp3', 'array': [-1.4210854715202004e-14, -8.171241461241152e-14, -5.950795411990839e-14, 7.993605777301127e-14, 1.6342482922482304e-13, 2.2737367544323206e-13, 3.126388037344441e-13, 4.050093593832571e-13, 3.979039320256561e-13, 7.105427357601002e-14, -5.044853423896711e-13, -8.100187187665142e-13, -4.689582056016661e-13, -8.526512829121202e-14, -1.3500311979441904e-13, -3.304023721284466e-13, -3.588240815588506e-13, 8.526512829121202e-14, 6.643574579356937e-13, 7.300826609935029e-13, 1.865174681370263e-13, 2.1316282072803006e-14, 5.542233338928781e-13, 8.171241461241152e-13, -2.1316282072803006e-14, -9.485745522397337e-13, -8.242295734817162e-13, -1.5631940186722204e-13, -2.984279490192421e-13, -1.4352963262354024e-12, -1.9326762412674725e-12, -5.542233338928781e-13, 1.4210854715202004e-12, 1.5774048733874224e-12, 3.410605131648481e-13, 4.973799150320701e-13, 3.055333763768431e-12, 5.350386800273554e-12, 4.080291660102375e-12, -7.238654120556021e-13, -5.39124300757976e-12, -7.080558361849398e-12, -6.066258606551855e-12, -4.508393658397836e-12, -3.4994229736184934e-12, -2.4584778657299466e-12, 2.1316282072803006e-13, 4.75353090223507e-12, 8.57625082062441e-12, 8.164136033883551e-12, 2.9558577807620168e-12, -3.481659405224491e-12, -5.739408948102209e-12, -1.3038459201197838e-12, 5.945466341472638e-12, 9.338307904727117e-12, 7.464251439159852e-12, 4.68247662865906e-12, 4.746425474877469e-12, 7.105427357601002e-12, 8.924416761146858e-12, 7.613465413669473e-12, 2.4868995751603507e-12, -4.458655666894629e-12, -8.86757334228605e-12, -6.501466032204917e-12, 1.3429257705865894e-12, 6.0396132539608516e-12, 2.3590018827235326e-12, -3.410605131648481e-13, 1.34718902700115e-11, 4.18367562815547e-11, 6.042455424903892e-11, 4.8416382014693227e-11, 1.5347723092418164e-11, -8.22808488010196e-12, -7.005951374594588e-12, 2.8137492336099967e-12, -1.3660184094987926e-12, -1.8630430531629827e-11, -2.857802883227123e-11, -1.809041805245215e-11, 4.412470389070222e-12, 2.100364326906856e-11, 2.2534862864631577e-11, 1.4811263326919288e-11, 1.06368247543287e-11, 1.8808066215569852e-11, 3.5715430612981436e-11, 4.4142467459096224e-11, 2.744116045505507e-11, -8.384404281969182e-12, -3.33244543071487e-11, -2.112354735572808e-11, 2.2648549702353193e-11, 6.511058359137678e-11, 7.823786063454463e-11, 6.270184371715004e-11, 3.870326281685266e-11, 1.935873683578393e-11, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Sylvia Nagginda ni malkia wa Buganda akivaa mapambo ya Kisamburu wakati wa kutembelea Kenya</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4c11cefc72fff6427d224a69c1fcaa301f4561231c26e3a8d3b79b262a6a16b1f34b6832df8dff8d7b85d13b49715cec77019b96801ee9c6aedf2be9d02a9306</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_36387948.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_36387948.mp3', 'array': [4.547473508864641e-13, 2.9558577807620168e-12, 6.934897101018578e-12, 5.9117155615240335e-12, 3.979039320256561e-12, 2.7284841053187847e-12, 2.0463630789890885e-12, 3.410605131648481e-13, -7.389644451905042e-13, 5.684341886080801e-13, 1.3642420526593924e-12, 1.5916157281026244e-12, 1.3642420526593924e-12, -4.547473508864641e-13, -1.3642420526593924e-12, -1.8189894035458565e-12, 4.547473508864641e-13, 3.410605131648481e-12, 8.412825991399586e-12, 1.2732925824820995e-11, 1.6257217794191092e-11, 1.602984411874786e-11, 1.290345608140342e-11, 6.480149750132114e-12, -6.821210263296962e-13, -1.000444171950221e-11, -1.887201506178826e-11, -2.6773250283440575e-11, -2.8194335754960775e-11, -2.8194335754960775e-11, -2.2737367544323206e-11, -1.3642420526593924e-11, -2.2737367544323206e-12, 5.5138116294983774e-12, 7.275957614183426e-12, 4.092726157978177e-12, -5.4569682106375694e-12, -1.5916157281026244e-11, -2.1373125491663814e-11, -2.0236257114447653e-11, -1.7053025658242404e-11, -2.000888343900442e-11, -3.456079866737127e-11, -6.366462912410498e-11, -1.0732037480920553e-10, -1.4279066817834973e-10, -1.5143086784519255e-10, -1.2232703738845885e-10, -6.230038707144558e-11, 1.432454155292362e-11, 8.378719940083101e-11, 1.1533529686857946e-10, 9.481482265982777e-11, 4.1382008930668235e-11, -9.322320693172514e-12, -4.547473508864641e-12, 8.969891496235505e-11, 2.5724489205458667e-10, 4.4428816181607544e-10, 5.775291356258094e-10, 5.793481250293553e-10, 3.9472070056945086e-10, 2.637534635141492e-11, -4.433786671143025e-10, -9.014229362946935e-10, -1.2280452210688964e-09, -1.3301360013429075e-09, -1.1705196811817586e-09, -7.908056431915611e-10, -2.887645678129047e-10, 2.2657786757918075e-10, 6.336335900414269e-10, 8.202505341614597e-10, 7.148628355935216e-10, 3.013838068000041e-10, -3.7061909097246826e-10, -1.1691554391290992e-09, -1.8906121113104746e-09, -2.3184156816569157e-09, -2.2793074094806798e-09, -1.7143975128419697e-09, -7.228209142340347e-10, 4.5861270336899906e-10, 1.5222667570924386e-09, 2.164597390219569e-09, 2.2178028302732855e-09, 1.7357706383336335e-09, 9.620180208003148e-10, 2.0622792362701148e-10, -2.610249794088304e-10, -3.121840563835576e-10, -2.637534635141492e-11, 3.771560841414612e-10, 6.477662850556953e-10, 6.076703584767529e-10, 2.319211489520967e-10, -3.240074875066057e-10, -8.319602784467861e-10, -1.1193606042070314e-09, -1.0968506103381515e-09, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Ng'ombe zimepigwa risasi ingawa miguu yote ya mbele haikuvunjika.</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>644aedd5857bd771dcb89593ff0e12654b3229815ca9846be3b5567af0c99854e348d1deb361acfa8c244c2feaef6a37283940d0e4cb9017ae73f6a573f88cf4</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_34911566.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_34911566.mp3', 'array': [-1.8474111129762605e-13, -3.268496584496461e-13, -5.400124791776761e-13, -9.379164112033322e-13, -1.3642420526593924e-12, -1.9042545318370685e-12, -2.0179413695586845e-12, -1.8474111129762605e-12, -1.5347723092418164e-12, -1.1368683772161603e-12, -1.0231815394945443e-12, -1.3642420526593924e-12, -1.7053025658242404e-12, -1.3642420526593924e-12, -9.379164112033322e-13, -5.115907697472721e-13, -3.410605131648481e-13, -4.156675004196586e-13, -1.0800249583553523e-12, -1.8189894035458565e-12, -1.8189894035458565e-12, -1.2505552149377763e-12, -4.547473508864641e-13, -2.2737367544323206e-13, -3.979039320256561e-13, -1.2789769243681803e-13, 9.094947017729282e-13, 2.1742607714259066e-12, 3.382183422218077e-12, 3.808509063674137e-12, 2.8137492336099967e-12, 9.947598300641403e-13, 5.968558980384842e-13, 1.9042545318370685e-12, 4.916955731459893e-12, 8.910205906431656e-12, 1.0402345651527867e-11, 9.592326932761353e-12, 1.0459189070388675e-11, 1.4381384971784428e-11, 2.2112089936854318e-11, 3.240074875066057e-11, 4.0330405681743287e-11, 4.0380143673246494e-11, 3.306865892227506e-11, 2.2524204723595176e-11, 1.2647660696529783e-11, 7.105427357601002e-12, 5.343281372915953e-12, 1.7905676941154525e-12, -5.8690829973784275e-12, -1.2022383089060895e-11, -9.634959496906959e-12, 6.45172804070171e-12, 3.242917046009097e-11, 5.2082782531215344e-11, 4.8544279707130045e-11, 1.801936377887614e-11, -3.0382807381101884e-11, -7.722178452240769e-11, -9.978862181014847e-11, -8.969891496235505e-11, -5.5862869885459077e-11, -1.6541434888495132e-11, 1.27613475342514e-11, 2.3490542844228912e-11, 1.8708590232563438e-11, 6.764366844436154e-12, -1.0800249583553523e-11, -3.6209257814334705e-11, -6.80699940858176e-11, -1.0012257689595572e-10, -1.2170175978098996e-10, -1.2187229003757238e-10, -9.984546522900928e-11, -6.502887117676437e-11, -3.0524915928253904e-11, -5.9117155615240335e-12, 4.519051799434237e-12, -2.0747847884194925e-12, -2.955857780762017e-11, -8.219558367272839e-11, -1.5401724340335932e-10, -2.226272499683546e-10, -2.551416855567368e-10, -2.2663471099804156e-10, -1.3697842859983211e-10, -1.375610736431554e-11, 9.78843672783114e-11, 1.5614887161063962e-10, 1.4927081792848185e-10, 1.0032863428932615e-10, 4.3996806198265404e-11, 3.467448550509289e-12, -9.201528428093297e-12, 1.0373923942097463e-11, 6.23856521997368e-11, 1.467412857891759e-10, 2.5647750589996576e-10, 3.6408209780347534e-10, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Kutokana na aina ya mziki wake aliokuwa anautunga</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a94f5f13bc64080cbf76d048be31efb215b078c2b48c5705ec37f6179a72a614f744f4adb79a9b35fd26e53988d8be228a37dbad1b1761765b72f3d330664dbe</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_29795994.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_29795994.mp3', 'array': [-5.684341886080801e-13, -3.183231456205249e-12, -4.305888978706207e-12, -3.993250174971763e-12, -3.666400516522117e-12, -3.169020601490047e-12, -1.7905676941154525e-12, -3.836930773104541e-13, -1.9895196601282805e-13, -1.5916157281026244e-12, -3.467448550509289e-12, -1.7053025658242404e-12, 3.410605131648481e-12, 8.58335624798201e-12, 9.805489753489383e-12, 7.44648787076585e-12, 3.780087354243733e-12, -3.353761712787673e-12, -1.2107648217352107e-11, -1.6086687537608668e-11, -9.606537787476555e-12, 3.296918293926865e-12, 1.2050804798491299e-11, 1.057287590811029e-11, 2.2737367544323206e-13, -1.1596057447604835e-11, -1.5575096767861396e-11, -5.8548721426632255e-12, 1.4381384971784428e-11, 3.1519675758318044e-11, 3.26281224261038e-11, 1.2924772363476222e-11, -1.602984411874786e-11, -4.0188297134591267e-11, -5.303490979713388e-11, -4.845901457883883e-11, -2.594902070995886e-11, 7.30437932361383e-12, 2.8819613362429664e-11, 2.3874235921539366e-11, 6.59383658785373e-12, 6.821210263296962e-12, 3.234390533179976e-11, 6.116351869422942e-11, 7.975131666171364e-11, 9.526957001071423e-11, 1.0879830369958654e-10, 9.609379958419595e-11, 3.581135388230905e-11, -5.002220859751105e-11, -9.885070539894514e-11, -6.747313818777911e-11, 1.0771827874123119e-11, 5.644551492878236e-11, 3.6777692002942786e-11, -1.4807710613240488e-11, -6.701839083689265e-11, -1.2300915841478854e-10, -1.7553247744217515e-10, -1.935518412210513e-10, -1.6846968264871975e-10, -1.425064510840457e-10, -1.5495515981456265e-10, -1.8349055608268827e-10, -1.5552359400317073e-10, -4.922640073345974e-11, 6.843947630841285e-11, 1.319904185947962e-10, 1.5052137314341962e-10, 1.730313670122996e-10, 2.1606183508993126e-10, 2.616786787257297e-10, 2.9311308935575653e-10, 2.998490344907623e-10, 2.745537130977027e-10, 2.3135271476348862e-10, 2.0384050003485754e-10, 1.9247181626269594e-10, 1.3085355021758005e-10, -3.399236447876319e-11, -2.3868551579653285e-10, -3.5078073779004626e-10, -3.468585418886505e-10, -3.589093466871418e-10, -4.849027845921228e-10, -6.313030098681338e-10, -6.250502337934449e-10, -4.4303760660113767e-10, -1.9889512259396724e-10, 5.283595783112105e-11, 3.200284481863491e-10, 4.814637577510439e-10, 3.079776433878578e-10, -2.0111201592953876e-10, -6.441496225306764e-10, -5.725269147660583e-10, -1.546140993013978e-11, 5.20230969414115e-10, 6.499476512544788e-10, 5.171045813767705e-10, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Ni shule ya mafunzo ya vijana wa kike huku yote yakiwa na lengo</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>33b592d476cc447e5ca333cee6350f4e44083dd391be459478e0cd934747627491784c96ba32fb9f7a3e5ba7aa0dd5553e8fe67b919746d6b4b10282f1c4f8f1</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_30051042.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_30051042.mp3', 'array': [-5.115907697472721e-13, -1.2505552149377763e-12, -1.4210854715202004e-12, -6.821210263296962e-13, 1.3642420526593924e-12, 1.8189894035458565e-12, 1.7053025658242404e-12, 1.1084466677857563e-12, -2.2737367544323206e-13, -2.3874235921539366e-12, -5.002220859751105e-12, -8.29913915367797e-12, -1.000444171950221e-11, -9.57811607804615e-12, -8.526512829121202e-12, -4.433786671143025e-12, 2.7853275241795927e-12, 1.0231815394945443e-11, 1.1766587704187259e-11, 6.906475391588174e-12, -5.6559201766503975e-12, -2.5721647034515627e-11, -3.9477754398831166e-11, -3.105782298007398e-11, -5.400124791776761e-13, 3.433342499192804e-11, 5.3887561080046e-11, 4.615685611497611e-11, 1.6711965145077556e-11, -1.5205614545266144e-11, -3.342393029015511e-11, -3.069544618483633e-11, -9.777068044058979e-12, 1.9838353182421997e-11, 4.843059286940843e-11, 6.468781066359952e-11, 6.684786058031023e-11, 5.650235834764317e-11, 3.930722414224874e-11, 2.2396307031158358e-11, 5.4569682106375694e-12, -1.2732925824820995e-11, -2.5920599000528455e-11, -2.859223968698643e-11, -1.4551915228366852e-11, 1.2164491636212915e-11, 3.524291969370097e-11, 3.717559593496844e-11, 2.5011104298755527e-11, 1.6370904631912708e-11, 2.015099198615644e-11, 1.9554136088117957e-11, 3.865352482534945e-12, -7.73070496506989e-12, 1.9554136088117957e-11, 9.092104846786242e-11, 1.5830892152735032e-10, 1.5236878425639588e-10, 4.672529030358419e-11, -9.936229616869241e-11, -1.7223555914824829e-10, -1.0965095498249866e-10, 3.2457592169521376e-11, 1.205648914037738e-10, 4.445155354915187e-11, -1.8849277694243938e-10, -4.426965460879728e-10, -5.520632839761674e-10, -4.368985173641704e-10, -1.4017587091075256e-10, 2.1321966414689086e-10, 4.746851800518925e-10, 5.305196282279212e-10, 3.6357050703372806e-10, 5.775291356258094e-11, -2.6574298317427747e-10, -5.111928658152465e-10, -6.201048563525546e-10, -5.609592790278839e-10, -3.5126390685036313e-10, -1.0243184078717604e-10, 1.6086687537608668e-11, -6.389200279954821e-11, -2.1543655748246238e-10, -2.2993162929196842e-10, -1.8900436771218665e-11, 3.000195647473447e-10, 4.90899765281938e-10, 3.767581802094355e-10, 8.640199666842818e-12, -3.496154477033997e-10, -4.427249677974032e-10, -2.5067947717616335e-10, 1.91562321560923e-11, 1.560920281917788e-10, 1.5927525964798406e-10, 1.8900436771218665e-10, 3.1752733775647357e-10, 4.2155079427175224e-10, 3.6686742532765493e-10, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Mama huweka Olkererreti ambayo ni bangili iliyotengenezwa kwa kutumia mguu wa kulia wa kondoo</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a59598f0a310679014e8663eeed32c7408fa0b0922e9e3f4eb4a759eb199342345753267b9c0cc4116d838f73c7f4b49350b4bd646caee4ac50935b60186d9f3</td>\n",
              "      <td>/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_30314645.mp3</td>\n",
              "      <td>{'path': '/root/.cache/huggingface/datasets/downloads/extracted/4a443506d39b8b48fcc983dd5b38f1616acba3909b5a917d6302bbbe14aec72e/sw_train_0/common_voice_sw_30314645.mp3', 'array': [0.0, 2.2737367544323206e-13, -1.5916157281026244e-12, -7.958078640513122e-13, 2.9558577807620168e-12, 5.229594535194337e-12, 1.3642420526593924e-12, -2.5011104298755527e-12, -3.183231456205249e-12, 3.183231456205249e-12, 1.0231815394945443e-11, 1.1596057447604835e-11, 5.9117155615240335e-12, 6.821210263296962e-13, 1.1084466677857563e-12, -2.1600499167107046e-12, -1.4551915228366852e-11, -2.4101609596982598e-11, -2.05773176276125e-11, -7.503331289626658e-12, 5.9117155615240335e-12, 1.1141310096718371e-11, 5.229594535194337e-12, -1.3073986337985843e-12, 0.0, 1.2505552149377763e-12, -8.86757334228605e-12, -2.1373125491663814e-11, -1.5234036254696548e-11, 1.8417267710901797e-11, 5.4569682106375694e-11, 6.571099220309407e-11, 4.1154635255225e-11, 8.185452315956354e-12, -3.637978807091713e-12, -8.526512829121202e-12, -3.6493474908638746e-11, -7.594280759803951e-11, -7.753442332614213e-11, -9.549694368615746e-12, 6.957634468562901e-11, 6.548361852765083e-11, -2.7966962079517543e-11, -9.831069291976746e-11, -5.2239101933082566e-11, 5.3887561080046e-11, 5.911715561524034e-11, -8.776623872108757e-11, -2.355591277591884e-10, -2.0372681319713593e-10, -2.773958840407431e-11, 9.5042196335271e-11, 6.991740519879386e-11, 7.844391802791506e-12, 5.729816621169448e-11, 1.964508555829525e-10, 2.4488144845236093e-10, 8.901679393602535e-11, -1.6007106751203537e-10, -3.2153479878616054e-10, -3.7778136174893007e-10, -4.079083737451583e-10, -3.8176040106918663e-10, -2.0236257114447653e-10, 8.230927051045e-11, 3.0740920919924974e-10, 4.317826096666977e-10, 6.095888238633052e-10, 8.926690497901291e-10, 9.99875737761613e-10, 6.111804395914078e-10, -8.776623872108757e-11, -4.204139258945361e-10, 4.7066350816749036e-11, 9.526957001071423e-10, 1.53431756189093e-09, 1.4538272807840258e-09, 1.0363692126702517e-09, 7.119922429410508e-10, 4.961293598171324e-10, 1.5836576494621113e-10, -3.1468516681343317e-10, -6.889422365929931e-10, -8.624283509561792e-10, -8.863025868777186e-10, -6.416485121008009e-10, 8.139977580867708e-11, 9.877112461254e-10, 1.244416125700809e-09, 4.843059286940843e-10, -4.5156411943025887e-10, -3.134346115984954e-10, 9.086988939088769e-10, 1.6709691408323124e-09, 7.25094650988467e-10, -1.11504050437361e-09, -1.8080754671245813e-09, -7.612470653839409e-10, 3.3526248444104567e-10, -2.1793766791233793e-10, ...], 'sampling_rate': 48000}</td>\n",
              "      <td>Iddi Amin alilelewa na mama yake bila baba kijijini katika Uganda ya Kaskazini magharibi</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>twenties</td>\n",
              "      <td>female</td>\n",
              "      <td></td>\n",
              "      <td>sw</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",
        "train_dataset = train_dataset.remove_columns(columns_to_remove)\n",
        "validation_dataset = validation_dataset.remove_columns(columns_to_remove)\n",
        "test_dataset = test_dataset.remove_columns(columns_to_remove)\n"
      ],
      "metadata": {
        "id": "PXOH4ujCZY96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Regular expression to remove symbols since it does not map to any phoneme in the Swahili language"
      ],
      "metadata": {
        "id": "GzmTkQ98dYd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Modify the chars_to_remove_regex pattern to include the additional symbols\n",
        "chars_to_remove_regex = r'[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\'\\(\\)\\*\\=\\_`\\[\\]\\/\\*°ː’•…]'\n",
        "\n",
        "def remove_special_characters(batch):\n",
        "    batch[\"sentence\"] = re.sub(chars_to_remove_regex, '', batch[\"sentence\"]).lower()\n",
        "    return batch\n",
        "\n",
        "cv_swahili_train = train_dataset.map(remove_special_characters)\n",
        "cv_swahili_validate = validation_dataset.map(remove_special_characters)\n",
        "cv_swahili_test = test_dataset.map(remove_special_characters)\n"
      ],
      "metadata": {
        "id": "53kyz3wNfsj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_extra_characters(batch, column_name=\"sentence\"):\n",
        "    character_replacements = {\n",
        "        'µ': 'u',\n",
        "        'á': 'a',\n",
        "        'â': 'a',\n",
        "        'ã': 'a',\n",
        "        'å': 'a',\n",
        "        'é': 'e',\n",
        "        'è': 'e',\n",
        "        'ë': 'e',\n",
        "        'í': 'i',\n",
        "        'ï': 'i',\n",
        "        'ñ': 'n',\n",
        "        'ó': 'o',\n",
        "        'ö': 'o',\n",
        "        'ø': 'o',\n",
        "        'ú': 'u',\n",
        "        'š': 's',\n",
        "        'ū': 'u',\n",
        "        'μ': 'u',\n",
        "        'ụ': 'u'\n",
        "    }\n",
        "\n",
        "    for original, replacement in character_replacements.items():\n",
        "        batch[column_name] = re.sub(re.escape(original), replacement, batch[column_name])\n",
        "\n",
        "    # Remove multiple dots and tabs\n",
        "    batch[column_name] = re.sub(r'\\.\\.\\.+', '', batch[column_name])\n",
        "    batch[column_name] = re.sub(r'\\t', '', batch[column_name])\n",
        "\n",
        "    return batch\n",
        "\n",
        "cv_swahili_train = cv_swahili_train.map(replace_extra_characters)\n",
        "cv_swahili_validate = cv_swahili_validate.map(replace_extra_characters)\n",
        "cv_swahili_test = cv_swahili_test.map(replace_extra_characters)\n"
      ],
      "metadata": {
        "id": "2qcZSlt_gj-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extracting the Swahili phoneme from the dataset transcript\n"
      ],
      "metadata": {
        "id": "_jxXqf0Odg_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_all_chars(batch):\n",
        "  all_text = \" \".join(batch[\"sentence\"])\n",
        "  vocab = list(set(all_text))\n",
        "  return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
        "\n",
        "\n",
        "\n",
        "vocab_train = cv_swahili_train.map(extract_all_chars, batched=True, batch_size=-1, remove_columns=cv_swahili_train.column_names)\n",
        "vocab_validate = cv_swahili_validate.map(extract_all_chars, batched=True, batch_size=-1, remove_columns=cv_swahili_validate.column_names)\n",
        "vocab_test = cv_swahili_test.map(extract_all_chars, batched=True, batch_size=-1, remove_columns=cv_swahili_test.column_names)\n"
      ],
      "metadata": {
        "id": "mTFXxiK7hRtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert \"vocab\" column from each dataset to sets and union them\n",
        "vocab_set_train = set(vocab_train[\"vocab\"][0])\n",
        "vocab_set_validate = set(vocab_validate[\"vocab\"][0])\n",
        "vocab_set_test = set(vocab_test[\"vocab\"][0])\n",
        "\n",
        "# Merge vocabularies\n",
        "vocab_set = vocab_set_train | vocab_set_validate | vocab_set_test\n",
        "\n",
        "# Convert the result back to a list\n",
        "vocab_list = list(vocab_set)\n"
      ],
      "metadata": {
        "id": "YCwhLPJnJtaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict = {v: k for k, v in enumerate(sorted(vocab_list))}\n",
        "vocab_dict.pop('י', None)\n",
        "vocab_dict"
      ],
      "metadata": {
        "id": "93RQcj_zT9Kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c4335c-97fc-4393-96ae-4078e05db7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'a': 1,\n",
              " 'b': 2,\n",
              " 'c': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'f': 6,\n",
              " 'g': 7,\n",
              " 'h': 8,\n",
              " 'i': 9,\n",
              " 'j': 10,\n",
              " 'k': 11,\n",
              " 'l': 12,\n",
              " 'm': 13,\n",
              " 'n': 14,\n",
              " 'o': 15,\n",
              " 'p': 16,\n",
              " 'q': 17,\n",
              " 'r': 18,\n",
              " 's': 19,\n",
              " 't': 20,\n",
              " 'u': 21,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 24,\n",
              " 'y': 25,\n",
              " 'z': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
        "del vocab_dict[\" \"]"
      ],
      "metadata": {
        "id": "xKEQz54glH2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_dict)"
      ],
      "metadata": {
        "id": "-iUHRFUPlPMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e77d98-d102-4f15-cd0a-5ee895ebdf35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '|': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
        "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
        "len(vocab_dict)"
      ],
      "metadata": {
        "id": "yRCzzg0elXon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595b4435-761a-4fec-ab3b-eda3e42acd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('vocab.json', 'w') as vocab_file:\n",
        "    json.dump(vocab_dict, vocab_file)"
      ],
      "metadata": {
        "id": "BquzUzU6ld8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2CTCTokenizer\n",
        "\n",
        "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"./\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
      ],
      "metadata": {
        "id": "QVDjxIdYrMsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import create_repo\n",
        "create_repo(\"finetuning-wav2vec-large-swahili-asr-model_v10\")"
      ],
      "metadata": {
        "id": "nWQjDiRhx5aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_name = \"finetuning-wav2vec-large-swahili-asr-model_v10\"\n",
        "tokenizer.push_to_hub(repo_name)"
      ],
      "metadata": {
        "id": "V7g9iko0rRsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Wav2VecFeatureExtractor\n"
      ],
      "metadata": {
        "id": "Kl8BIBWXrR1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Speech is a continuous signal, and, to be treated by computers, it first has to be discretized, which is usually called sampling.\n",
        "The sampling rate hereby plays an important role since it defines how many data points of the speech signal are measured per second.\n",
        "Therefore, sampling with a higher sampling rate results in a better approximation of the real speech signal but also necessitates more values per second.\n",
        "\n",
        "A pretrained checkpoint expects its input data to have been sampled more or less from the same distribution as the data it was trained on.\n",
        "The same speech signals sampled at two different rates have a very different distribution. For example, doubling the sampling rate results in data points\n",
        " being twice as long. Thus, before fine-tuning a pretrained checkpoint of an ASR model,\n",
        " it is crucial to verify that the sampling rate of the data that was used to pretrain the model matches the sampling rate of the dataset\n",
        " used to fine-tune the model.\n",
        "\n",
        "XLS-R was pretrained on audio data of Babel, Multilingual LibriSpeech (MLS), Common Voice, VoxPopuli, and VoxLingua107 at a sampling rate of 16kHz\n",
        " Common Voice, in its original form, has a sampling rate of 48kHz, thus we will have to downsample the fine-tuning data to 16kHz in the following.\n",
        "\n",
        "XLS-R was pretrained on audio data of Babel, Multilingual LibriSpeech (MLS), Common Voice, VoxPopuli, and VoxLingua107 at a sampling rate of 16kHz.\n",
        "Common Voice, in its original form, has a sampling rate of 48kHz, thus we will have to downsample the fine-tuning data to 16kHz in the following.\n",
        "\n",
        "A Wav2Vec2FeatureExtractor object requires the following parameters to be instantiated:\n",
        "\n",
        "1. Feature_size: Speech models take a sequence of feature vectors as an input. While the length of this sequence obviously varies,\n",
        " the feature size should not. In the case of Wav2Vec2, the feature size is 1 because the model was trained on the raw speech signal\n",
        "\n",
        "2. Sampling_rate: The sampling rate at which the model is trained on.\n",
        "padding_value: For batched inference, shorter inputs need to be padded with a specific value\n",
        "\n",
        "3. Do_normalize: Whether the input should be zero-mean-unit-variance normalized or not. Usually, speech models perform better when normalizing the input\n",
        "return_attention_mask: Whether the model should make use of an attention_mask for batched inference.\n",
        "In general, XLS-R models checkpoints should always use the attention_mask."
      ],
      "metadata": {
        "id": "cRPAoxGPrR7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2FeatureExtractor\n",
        "\n",
        "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n"
      ],
      "metadata": {
        "id": "93-7BVYdrSI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##preprocess data"
      ],
      "metadata": {
        "id": "7BEgQ7birSRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_swahili_train[0][\"audio\"]"
      ],
      "metadata": {
        "id": "VNFSwCTDu5jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric, Audio\n",
        "cv_swahili_train = cv_swahili_train.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "cv_swahili_validate = cv_swahili_validate.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
        "cv_swahili_test = cv_swahili_test.cast_column(\"audio\", Audio(sampling_rate=16_000))"
      ],
      "metadata": {
        "id": "sFNkVtKorSZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_swahili_train[0][\"audio\"]"
      ],
      "metadata": {
        "id": "uVROZ411rSif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "rand_int = random.randint(0, len(cv_swahili_train)-1)\n",
        "\n",
        "print(cv_swahili_train[rand_int][\"sentence\"])\n",
        "ipd.Audio(data=cv_swahili_train[rand_int][\"audio\"][\"array\"], autoplay=True, rate=16000)"
      ],
      "metadata": {
        "id": "2SLwPtJMw96d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_int = random.randint(0, len(cv_swahili_train)-1)\n",
        "\n",
        "print(\"Target text:\", cv_swahili_train[rand_int][\"sentence\"])\n",
        "print(\"Input array shape:\", cv_swahili_train[rand_int][\"audio\"][\"array\"].shape)\n",
        "print(\"Sampling rate:\", cv_swahili_train[rand_int][\"audio\"][\"sampling_rate\"])"
      ],
      "metadata": {
        "id": "iExeol6pvFK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprocess the dataset to the format expected by Wave2Vec2ForCTC leveraging Wav2Vec2Processor"
      ],
      "metadata": {
        "id": "tsvtEeXYvFVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # batched output is \"un-batched\"\n",
        "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
        "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
        "\n",
        "    with processor.as_target_processor():\n",
        "        batch[\"labels\"] = processor(batch[\"sentence\"]).input_ids\n",
        "    return batch"
      ],
      "metadata": {
        "id": "42KsG-JCvFtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_swahili_train = cv_swahili_train.map(prepare_dataset, remove_columns=cv_swahili_train.column_names)\n",
        "cv_swahili_validate = cv_swahili_validate.map(prepare_dataset, remove_columns=cv_swahili_validate.column_names)\n",
        "cv_Swahili_test = cv_swahili_test.map(prepare_dataset, remove_columns=cv_swahili_test.column_names)"
      ],
      "metadata": {
        "id": "_VjwtNHYyli8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "# Concatenate cv_swahili_train and cv_swahili_validate\n",
        "combined_train_validate = concatenate_datasets([cv_swahili_train, cv_swahili_validate])"
      ],
      "metadata": {
        "id": "Q7dZHKB5ylsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##training"
      ],
      "metadata": {
        "id": "D1UD5w5WylzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The data is processed so that we are ready to start setting up the training pipeline. We will make use of 🤗's Trainer\n",
        " for which we essentially need to do the following:\n",
        "\n",
        "Define a data collator. In contrast to most NLP models, XLS-R has a much larger input length than output length.\n",
        "E.g., a sample of input length 50000 has an output length of no more than 100. Given the large input sizes,\n",
        "it is much more efficient to pad the training batches dynamically meaning that all training samples should only be padded to the\n",
        "longest sample in their batch and not the overall longest sample. Therefore, fine-tuning XLS-R requires a special padding data collator, which we will define below\n",
        "\n",
        "Evaluation metric. During training, the model should be evaluated on the word error rate. We should define a compute_metrics function accordingly\n",
        "\n",
        "Load a pretrained checkpoint. We need to load a pretrained checkpoint and configure it correctly for training.\n",
        "\n",
        "Define the training configuration."
      ],
      "metadata": {
        "id": "2n8KDEGN9TGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs received.\n",
        "    Args:\n",
        "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
        "            The processor used for proccessing the data.\n",
        "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
        "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
        "            among:\n",
        "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
        "              sequence if provided).\n",
        "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
        "              maximum acceptable input length for the model if that argument is not provided.\n",
        "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
        "              different lengths).\n",
        "    \"\"\"\n",
        "\n",
        "    processor: Wav2Vec2Processor\n",
        "    padding: Union[bool, str] = True\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need\n",
        "        # different padding methods\n",
        "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "\n",
        "        batch = self.processor.pad(\n",
        "            input_features,\n",
        "            padding=self.padding,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        with self.processor.as_target_processor():\n",
        "            labels_batch = self.processor.pad(\n",
        "                label_features,\n",
        "                padding=self.padding,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ],
      "metadata": {
        "id": "bZLIfgPu9dKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
      ],
      "metadata": {
        "id": "RvqytGL49dlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wer_metric = load_metric(\"wer\")"
      ],
      "metadata": {
        "id": "qZ-PHTHM9dvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "\n",
        "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
        "\n",
        "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ],
      "metadata": {
        "id": "_oZQrrnx9d4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rom transformers import Wav2Vec2ForCTC, AutoModelForCTC\n",
        "\n",
        "# model = Wav2Vec2ForCTC.from_pretrained(\n",
        "#     \"facebook/wav2vec2-xls-r-300m\",\n",
        "#     ctc_loss_reduction=\"mean\",\n",
        "#     pad_token_id=processor.tokenizer.pad_token_id,\n",
        "#     vocab_size=len(processor.tokenizer),\n",
        "# )\n",
        "#model = AutoModelForCTC.from_pretrained(\"AntonyG/fine-tune-wav2vec2-large-xls-r-1b-sw\")\n",
        "model = AutoModelForCTC.from_pretrained(\"Joshua-Abok/finetuned_wav2vec_asr\")\n",
        "# model.enable_input_require_grads()"
      ],
      "metadata": {
        "id": "32hfdpBL9d__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cuda\")\n",
        "model.freeze_feature_extractor()"
      ],
      "metadata": {
        "id": "Q3uKiac9aCHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n"
      ],
      "metadata": {
        "id": "dVDpcUkHaE19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# lora_config = LoraConfig(\n",
        "#     r=16, # Rank\n",
        "#     lora_alpha=32,\n",
        "#     target_modules=[\"q_proj\", \"v_proj\"],\n",
        "#     lora_dropout=0.05,\n",
        "#     bias=\"none\",\n",
        "# )\n",
        "# model = get_peft_model(model, lora_config)\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ],
      "metadata": {
        "id": "qr4QcRvcaE-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, get_linear_schedule_with_warmup\n",
        "\n",
        "# Check if you are running on a CUDA-enabled device before enabling FP16\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    fp16_enabled = True\n",
        "else:\n",
        "    fp16_enabled = False\n",
        "    print(\"CUDA device not available. Disabling FP16.\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=repo_name,\n",
        "  group_by_length=True,\n",
        "  per_device_train_batch_size=16,\n",
        "  gradient_accumulation_steps=2,\n",
        "  evaluation_strategy=\"steps\",\n",
        "  num_train_epochs=15,\n",
        "  gradient_checkpointing=True,\n",
        "  fp16=fp16_enabled,  # Enable FP16 only if CUDA is available\n",
        "  save_steps=400,\n",
        "  eval_steps=400,\n",
        "  logging_steps=400,\n",
        "  learning_rate=3e-4,\n",
        "  warmup_steps=500,\n",
        "  save_total_limit=2,\n",
        "  push_to_hub=True,\n",
        "  remove_unused_columns=False\n",
        ")\n",
        "\n",
        "# Define the scheduler parameters\n",
        "num_warmup_steps = int(training_args.max_steps * 0.1)"
      ],
      "metadata": {
        "id": "TKphbEhTaFHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pass all instances to Trainer, ready for training"
      ],
      "metadata": {
        "id": "GQiSfZy9aFP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "# from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.optim import AdamW\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=combined_train_validate,\n",
        "    eval_dataset=cv_Swahili_test,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")\n",
        "\n",
        "# Create the learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n",
        "# scheduler = OneCycleLR(\n",
        "#     optimizer,\n",
        "#     total_steps=1000,\n",
        "#     epochs=training_args.num_train_epochs,\n",
        "#     steps_per_epoch=len(cv_swahili_train),\n",
        "#     pct_start=0.3,  # Percentage of the cycle that's a rising learning rate\n",
        "#     max_lr=4*training_args.learning_rate,    # peak learning rate\n",
        "#     final_div_factor=25.0,  # in the end LR will decay to initial_LR/final_div_factor\n",
        "# )\n",
        "total_steps = 1000\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=total_steps,\n",
        "    eta_min=0,  # Minimum learning rate\n",
        ")\n",
        "\n",
        "# Define a function to update the learning rate during training\n",
        "def update_lr():\n",
        "  scheduler.step()"
      ],
      "metadata": {
        "id": "S6uJMEsLa_QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if this is the correct implementation of the CosineAnnealingLR. It looks like a better learning rate schedulers.\n",
        "# from torch.optim import AdamW\n",
        "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n",
        "# total_steps = 1000\n",
        "# epochs = training_args.num_train_epochs\n",
        "# steps_per_epoch = len(cv_swahili_train)\n",
        "\n",
        "# scheduler = CosineAnnealingLR(\n",
        "#     optimizer,\n",
        "#     T_max=total_steps,\n",
        "#     eta_min=0,  # Minimum learning rate\n",
        "# )"
      ],
      "metadata": {
        "id": "WBPVqEaqa_b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "To allow models to become independent of the speaker rate, in CTC, consecutive tokens that are identical are simply grouped\n",
        " as a single token. However, the encoded labels should not be grouped when decoding since they don't correspond to the predicted tokens of the model,\n",
        " which is why the group_tokens=False parameter has to be passed. If we wouldn't pass this parameter a word like \"hello\" would incorrectly be encoded,\n",
        " and decoded as \"helo\". 2 2 The blank token allows the model to predict a word, such as \"hello\" by\n",
        " forcing it to insert the blank token between the two l's. A CTC-conform prediction of \"hello\" of our\n",
        "  model would be [PAD] [PAD] \"h\" \"e\" \"e\" \"l\" \"l\" [PAD] \"l\" \"o\" \"o\" [PAD].\n",
        "\n"
      ],
      "metadata": {
        "id": "6d-MmcJJa_mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "iVkToSTka_uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(training_args.num_train_epochs):\n",
        "    trainer.train()\n",
        "    update_lr()\n",
        "    trainer.evaluate()"
      ],
      "metadata": {
        "id": "hOkv9UgKa_2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "9ynQMXn6a_-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()    #had quotes -> (\"\")"
      ],
      "metadata": {
        "id": "GUAsVS6ybAGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"../\")"
      ],
      "metadata": {
        "id": "dOxTUm-TbAOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "AfqgYF_xbAV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone \"https://huggingface.co/Joshua-Abok/finetuning-wav2vec-large-swahili-asr-model_v9\""
      ],
      "metadata": {
        "id": "zMjwSbv_b4vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pwd"
      ],
      "metadata": {
        "id": "YyBGtOdhb45w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir(\"/content/finetuning-wav2vec-large-swahili-asr-model_v9\")"
      ],
      "metadata": {
        "id": "AgvZH1B5b5d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pwd"
      ],
      "metadata": {
        "id": "g9uHqr55b5q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "Z27FXsc1b53C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/finetuning-wav2vec-large-swahili-asr-model_v9/\""
      ],
      "metadata": {
        "id": "BmJqAL6-cRWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "JG6bBdWNcRfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/var/log/colab-jupyter.log\", \"r\") as fo:\n",
        "  for line in fo:\n",
        "    print(json.loads(line)['msg'])"
      ],
      "metadata": {
        "id": "ip-YOUaDcRnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from pydub import AudioSegment\n",
        "#from datasets import load_dataset\n",
        "\n",
        "#def convert_mp3_to_wav(input_dataset, output_dataset):\n",
        "\n",
        "    #for i in range(len(input_dataset)):\n",
        "        # Load MP3 audio file from input dataset\n",
        "        #mp3_audio_path = input_dataset[i]['path']\n",
        "        #audio = AudioSegment.from_mp3(mp3_audio_path)\n",
        "\n",
        "        # Export audio to WAV format and update the output dataset with the WAV file path\n",
        "        #wav_audio_path = mp3_audio_path.replace(\".mp3\", \".wav\")\n",
        "        #audio.export(wav_audio_path, format=\"wav\")\n",
        "\n",
        "        # Update the output dataset with the WAV file path\n",
        "        #output_dataset[i]['path'] = wav_audio_path\n",
        "\n",
        "# Example usage\n",
        "# Load input datasets\n",
        "#train_set = train_dataset\n",
        "#validation_set = validation_dataset\n",
        "#test_set = test_dataset\n",
        "\n",
        "# Create output datasets with the same structure as the input datasets\n",
        "#converted_train_dataset = train_dataset.copy()\n",
        "#converted_validation_dataset = validation_dataset.copy()\n",
        "#converted_test_dataset = test_dataset.copy()\n",
        "\n",
        "# Convert MP3 to WAV and update the output datasets\n",
        "#convert_mp3_to_wav(train_set, converted_train_dataset)\n",
        "#convert_mp3_to_wav(validation_set, converted_validation_dataset)\n",
        "#convert_mp3_to_wav(test_set, converted_test_dataset)"
      ],
      "metadata": {
        "id": "KNo2eH_8sIrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import json\n",
        "#from tqdm import tqdm\n",
        "\n",
        "#validation_manifest = validation_dataset.json\n",
        "#test_manifest = test_dataset.json\n",
        "#train_manifest =train_dataset.json\n",
        "#def compute_char_counts(manifest):\n",
        "  #char_counts = {}\n",
        "  #with open(manifest, 'r') as fn_in:\n",
        "      #for line in tqdm(fn_in, desc=\"Compute counts..\"):\n",
        "          #line = line.replace(\"\\n\", \"\")\n",
        "          #data = json.loads(line)\n",
        "          #text = data[\"text\"]\n",
        "          #for word in text.split():\n",
        "              #for char in word:\n",
        "                  #if char not in char_counts:\n",
        "                      #char_counts[char] = 1\n",
        "                  #else:\n",
        "                      #char_counts[char] += 1\n",
        "  #return char_counts\n",
        "\n",
        "#char_counts = compute_char_counts(train_manifest)\n",
        "\n",
        "#threshold = 10\n",
        "#trash_char_list = []\n",
        "\n",
        "#for char in char_counts:\n",
        "  #if char_counts[char] <= threshold:\n",
        "      #trash_char_list.append(char)\n",
        "#Let's check:\n",
        "\n",
        "3print(trash_char_list)"
      ],
      "metadata": {
        "id": "-lFAKIWyN64q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}